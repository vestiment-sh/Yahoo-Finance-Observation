{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steven Smith, King Ting Helen Wong, Zeqing Yan\n",
    "## Professor Abu Kamruzzaman\n",
    "## Programming for Analytics (CIS 3120-NFA)\n",
    "## 20 November 2020                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3 align=\"center\">Yahoo Finance Overview</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from lxml import html\n",
    "import requests\n",
    "import json\n",
    "import argparse\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching HTML title\n",
    "def get_headers():\n",
    "    return {\"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "            \"accept-encoding\": \"gzip, deflate, br\",\n",
    "            \"accept-language\": \"en-GB,en;q=0.9,en-US;q=0.8,ml;q=0.7\",\n",
    "            \"cache-control\": \"max-age=0\",\n",
    "            \"dnt\": \"1\",\n",
    "            \"sec-fetch-dest\": \"document\",\n",
    "            \"sec-fetch-mode\": \"navigate\",\n",
    "            \"sec-fetch-site\": \"none\",\n",
    "            \"sec-fetch-user\": \"?1\",\n",
    "            \"upgrade-insecure-requests\": \"1\",\n",
    "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going through contents, specific to the company we are scrapping financial data for\n",
    "def parse(ticker):\n",
    "    url = \"http://finance.yahoo.com/quote/%s?p=%s\" % (ticker, ticker)\n",
    "    response = requests.get(\n",
    "        url, verify=False, headers=get_headers(), timeout=30)\n",
    "    print(\"Parsing %s\" % (url))\n",
    "    parser = html.fromstring(response.text)\n",
    "    summary_table = parser.xpath(\n",
    "        '//div[contains(@data-test,\"summary-table\")]//tr')\n",
    "    summary_data = OrderedDict()\n",
    "    other_details_json_link = \"https://query2.finance.yahoo.com/v10/finance/quoteSummary/{0}?formatted=true&lang=en-US&region=US&modules=summaryProfile%2CfinancialData%2CrecommendationTrend%2CupgradeDowngradeHistory%2Cearnings%2CdefaultKeyStatistics%2CcalendarEvents&corsDomain=finance.yahoo.com\".format(\n",
    "        ticker)\n",
    "    summary_json_response = requests.get(other_details_json_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching specific financial data that we want such as target mean price and earnings\n",
    "    try:\n",
    "        json_loaded_summary = json.loads(summary_json_response.text)\n",
    "        summary = json_loaded_summary[\"quoteSummary\"][\"result\"][0]\n",
    "        y_Target_Est = summary[\"financialData\"][\"targetMeanPrice\"]['raw']\n",
    "        earnings_list = summary[\"calendarEvents\"]['earnings']\n",
    "        eps = summary[\"defaultKeyStatistics\"][\"trailingEps\"]['raw']\n",
    "        datelist = []\n",
    "\n",
    "        for i in earnings_list['earningsDate']:\n",
    "            datelist.append(i['fmt'])\n",
    "        earnings_date = ' to '.join(datelist)\n",
    "\n",
    "        for table_data in summary_table:\n",
    "            raw_table_key = table_data.xpath(\n",
    "                './/td[1]//text()')\n",
    "            raw_table_value = table_data.xpath(\n",
    "                './/td[2]//text()')\n",
    "            table_key = ''.join(raw_table_key).strip()\n",
    "            table_value = ''.join(raw_table_value).strip()\n",
    "            summary_data.update({table_key: table_value})\n",
    "        summary_data.update({'1y Target Est': y_Target_Est, 'EPS (TTM)': eps,'Earnings Date': earnings_date, 'ticker': ticker,'url': url})\n",
    "                return summary_data\n",
    "    except ValueError:\n",
    "        print(\"Failed to parse json response\")\n",
    "        return {\"error\": \"Failed to parse json response\"}\n",
    "    except:\n",
    "        return {\"error\": \"Unhandled Error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('ticker', help='')\n",
    "    args = argparser.parse_args()\n",
    "    ticker = args.ticker\n",
    "    print(\"Fetching data for %s\" % (ticker))\n",
    "    scraped_data = parse(ticker)\n",
    "    print(\"Writing data to output file\")\n",
    "    with open('%s-summary.json' % (ticker), 'w') as fp:\n",
    "        json.dump(scraped_data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are using numpy as well as panda to compute the sharpe ratio, a financial ratio that measures an investment's return compare to its risk, over certain number of days.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sharpe ratio of cumulative returns of 100 days \n",
    "N = 100\n",
    "R = pd.DataFrame(np.random.normal(size=100)).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (R - R.shift(1))/R.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "source = requests.get('https://finance.yahoo.com/quote/AMZN/key-statistics?p=AMZN').text\n",
    "\n",
    "soup = BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('div',class_='M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)')\n",
    "\n",
    "tr = table.find('tr',class_='Bdtw(0px) C($primaryColor)')\n",
    "\n",
    "current = tr.find_all('span')[2].text\n",
    "first = tr.find_all('span')[3].text\n",
    "second = tr.find_all('span')[4].text\n",
    "third = tr.find_all('span')[5].text \n",
    "fourth = tr.find_all('span')[6].text\n",
    "\n",
    "print(current,first,second,third,fourth)\n",
    "\n",
    "tbody = table.find('tbody')\n",
    "\n",
    "for tr in tbody.find_all('tr'):\n",
    "    data_type = tr.find_all('span')[0].text\n",
    "    current = tr.find_all('td')[1].text\n",
    "    first = tr.find_all('td')[2].text\n",
    "    second = tr.find_all('td')[3].text\n",
    "    third = tr.find_all('td')[4].text\n",
    "    fourth = tr.find_all('td')[5].text\n",
    "    print(data_type,current,first,second,third,fourth)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing/saving as csv file\n",
    "df = pd.DataFrame({'Amazondata':['Market Cap (intraday)','Enterprise Value','Trailing P/E','Forward P/E','PEG Ratio (5 yr expected)','Price/Sales','Price/Book','Enterprise Value/Revenue','Enterprise Value/EBITDA'],\n",
    "                   'current':['1.59T','1.60T','122.08','58.14','1.19','5.00','21.58','4.96','39.12'],\n",
    "                    '6/30/2020':[ '1.38T', '1.40T', '131.81',  '128.21', '2.97', '4.70', '21.18', '15.71', '112.89' ],\n",
    "                    '3/31/2020':['972.91B','981.09B', '84.73', '66.23','1.50','3.50','15.68','13.00','107.26'] ,\n",
    "                    '12/31/2019':['920.22B','936.35B','81.87','58.14','1.32','3.50','16.28','10.71','87.69'],\n",
    "                   '9/30/2019':['859.28B','876.28B','72.00','44.84','1.02','3.46','16.19','12.52','102.00']})\n",
    "\n",
    "                                  \n",
    "df    \n",
    "df.to_csv('Users/Jackie333/Desktop/data.csv')\n",
    "df.isnull()\n",
    "(df.isnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_file = np.loadtxt('Users/Jackie333/Desktop/data.csv', delimiter=',')\n",
    "\n",
    "time =data_file[:,0]\n",
    "\n",
    "time = time - time[0]\n",
    "\n",
    "sensors =data_file[:,1:5]\n",
    "\n",
    "avg = np.mean(sensors,axis=1)\n",
    "\n",
    "my_data = np.vstack((time,sensors.T,avg))\n",
    "my_data = my_data.T\n",
    "np.savetxt('export.csv',my_data,delimiter=',')\n",
    "\n",
    "plt.plot(time/60,sensors[:,1],'ro')\n",
    "plt.plot(time/60,avg,'b')\n",
    "plt.legend(['Sensor 2','Average'], loc='best')\n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel('Values')\n",
    "plt.savefig('my_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "d = pd.date_range(start='1/1/2008', end='12/1/2015')\n",
    "df = pd.DataFrame(d, columns=['Date'])\n",
    "df['returns'] = np.random.rand(d.size, 1)\n",
    "df = df.set_index('Date')\n",
    "\n",
    "df['Users/Jackie333/Desktop/data.csv'] = df.returns.rolling(180).apply(lambda x: (x.mean() - 0.02) / x.std(), raw = True)\n",
    "df.fillna(0, inplace = True)\n",
    "df[df['Users/Jackie333/Desktop/data.csv'] > 0].rolling_SR.plot(style='-', lw=3, color='orange', label='Sharpe', figsize = (10,7))\\.axhline(y = 1.6, color = \"blue\", lw = 3,linestyle = '--')\n",
    "\n",
    "plt.ylabel('Sharpe ratio')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Sharpe ratio (6-month)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
